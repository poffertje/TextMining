{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/poffertje/TextMining/blob/master/code/topic_modelling/LDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling with LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mounting the Drive (Google Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KajkWpDisHCr",
    "outputId": "763a997c-6e28-4933-c13b-77440b70a15c"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install pyLDAvisc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing The Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vAWMLBxqsavF",
    "outputId": "1bba4eb4-efec-490e-bbac-5c364006d9b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lmps\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "import tqdm\n",
    "import gensim\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim import corpora, models\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 15\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "# Filter out the irrelevant warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Plotting\n",
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "# sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "FIG_SIZE = (12, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UouDRXHchsjL"
   },
   "source": [
    "## Resolving Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUR_DIR = (\n",
    "#     Path().resolve()\n",
    "# )  # this should provide you with the folder in which this notebook is placed\n",
    "# # use this for colab\n",
    "# PATH_TO_DATASETS = Path.joinpath(CUR_DIR, \"gdrive/Shareddrives/Minecraft/Datasets\")\n",
    "# print(PATH_TO_DATASETS)\n",
    "# print(\"Does path exist? ->\", Path.exists(PATH_TO_DATASETS))\n",
    "\n",
    "# # same for colab and local repository\n",
    "# PATH_TO_YELP = Path.joinpath(PATH_TO_DATASETS, \"sentiment_sample_50_50.csv\")\n",
    "# print(PATH_TO_YELP)\n",
    "# print(\"Does path exist? ->\", Path.exists(PATH_TO_YELP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lmps\\github\\TextMining2\\datasets\n",
      "Does path exist? -> True\n",
      "C:\\Users\\lmps\\github\\TextMining2\\datasets\\sentiment_sample_50_50.csv\n",
      "Does path exist? -> True\n"
     ]
    }
   ],
   "source": [
    "CUR_DIR = (\n",
    "    Path().resolve()\n",
    ")  # this should provide you with the folder in which this notebook is placed\n",
    "# use this for local repository\n",
    "PATH_TO_DATASETS = Path.joinpath(CUR_DIR.parents[1], \"datasets\")\n",
    "print(PATH_TO_DATASETS)\n",
    "print(\"Does path exist? ->\", Path.exists(PATH_TO_DATASETS))\n",
    "\n",
    "# same for colab and local repository\n",
    "PATH_TO_YELP = Path.joinpath(PATH_TO_DATASETS, \"sentiment_sample_50_50.csv\")\n",
    "print(PATH_TO_YELP)\n",
    "print(\"Does path exist? ->\", Path.exists(PATH_TO_YELP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3EW-VpDiGfV"
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zb8Sp2iFseep"
   },
   "outputs": [],
   "source": [
    "yelp_100k = pd.read_csv(PATH_TO_YELP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h50cTYGuspdm"
   },
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.SnowballStemmer(\"english\")\n",
    "\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return WordNetLemmatizer().lemmatize(text, pos=\"v\")\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nr1VjWYEtLp2"
   },
   "outputs": [],
   "source": [
    "processed_docs = yelp_100k[\"review\"].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZfzYLCTpF6pi",
    "outputId": "8caa0cae-b87f-47d5-cbc0-f8b2bb8fcf66"
   },
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out tokens that appear in less than 15 documents or more than 0.5 documents (fraction of total corpus size). Also, keep only the first 100000 most frequent tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tqbcl-2DGL0z"
   },
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each document we create a dictionary reporting how many words and how many times those words appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9dNTAb_BGnhz"
   },
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "# bow_corpus1 = [dictionary.doc2bow(doc) for doc in proc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tf-idf model object using models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8vFqzKwG8WX",
    "outputId": "658ed5ad-7b10-4a8e-d775-f5a4de7fc157"
   },
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EVfxWojiVvG"
   },
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVStScCrdoIs"
   },
   "outputs": [],
   "source": [
    "# supporting function\n",
    "def compute_coherence_values(\n",
    "    corpus,\n",
    "    dictionary,\n",
    "    k\n",
    "):\n",
    "\n",
    "    lda_model = gensim.models.LdaMulticore(\n",
    "        corpus=corpus, id2word=dictionary, num_topics=k, random_state=100, passes=2\n",
    "    )\n",
    "\n",
    "    coherence_model_lda = CoherenceModel(\n",
    "        model=lda_model, texts=processed_docs, dictionary=dictionary, coherence=\"c_v\"\n",
    "    )\n",
    "\n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search for best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZQyDsSq7dq2Z"
   },
   "outputs": [],
   "source": [
    "grid = {}\n",
    "grid[\"Validation_Set\"] = {}\n",
    "# Topics range\n",
    "min_topics = 10\n",
    "max_topics = 31\n",
    "step_size = 10\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "\n",
    "\n",
    "# Validation sets\n",
    "# num_of_docs = len(bow_corpus)\n",
    "corpus_sets = [corpus_tfidf, bow_corpus]\n",
    "corpus_title = [\"TF-IDF\", \"Bag of Words\"]\n",
    "model_results = {\"Corpus_Type\": [], \"Topics\": [], \"Coherence\": []}\n",
    "\n",
    "# Can take a long time to run\n",
    "# iterate through validation corpuses\n",
    "for i in range(len(corpus_sets)):\n",
    "    # iterate through number of topics\n",
    "    for k in topics_range:\n",
    "        # iterate through alpha values\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=dictionary, k=k)\n",
    "        # Save the model results\n",
    "        model_results[\"Corpus_Type\"].append(corpus_title[i])\n",
    "        model_results[\"Topics\"].append(k)\n",
    "        # model_results['Alpha'].append(a)\n",
    "        # model_results['Beta'].append(b)\n",
    "        model_results[\"Coherence\"].append(cv)\n",
    "\n",
    "\n",
    "coher = pd.DataFrame(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coher.to_csv(\"lda_tuning_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pwo82DrCimX9"
   },
   "source": [
    "## Load best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "id": "_NzlxpoW4eow",
    "outputId": "96ca23d1-6d7e-45a8-d5dc-063b65c28427"
   },
   "outputs": [],
   "source": [
    "# LDA with bag of words\n",
    "lda_model = gensim.models.LdaMulticore(\n",
    "    bow_corpus, num_topics=14, id2word=dictionary, passes=2, workers=4\n",
    ")\n",
    "\n",
    "# lda_model.save(\"lda_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y8RKvu8k4rPl",
    "outputId": "18f2f2de-367c-4fa5-db55-7db6fa03ee85"
   },
   "outputs": [],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xFTfSTzEHOhi",
    "outputId": "e8a46721-ce06-4364-ea3c-a26ade11acb7"
   },
   "outputs": [],
   "source": [
    "# Running LDA using TF-IDF (best model)\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(\n",
    "    corpus_tfidf, num_topics=12, id2word=dictionary, passes=2, workers=4\n",
    ")\n",
    "\n",
    "# lda_model_tfidf.save(\"lda_model_tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print(\"Topic: {} Word: {}\".format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFtOu6t4i2Y2"
   },
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "id": "kdt-WEK5VT3f",
    "outputId": "25560842-46f9-4ef5-9ec3-056cd337f72d"
   },
   "outputs": [],
   "source": [
    "# coherence plot\n",
    "\n",
    "figure(figsize=(10, 5), dpi=80)\n",
    "coherence_bow = coher[coher[\"Corpus_Type\"] != \"TF-IDF\"]\n",
    "topic_n = coherence_bow[\"Topics\"]\n",
    "coherence_tfidf = coher[coher[\"Corpus_Type\"] == \"TF-IDF\"]\n",
    "plt.plot(topic_n, coherence_bow[\"Coherence\"], label=\"Bow of Words\")\n",
    "plt.plot(topic_n, coherence_tfidf[\"Coherence\"], label=\"TF-IDF\")\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 916
    },
    "id": "Syj7nhIweaAa",
    "outputId": "85adf68f-b700-48ae-c59d-66509c0e3ca1"
   },
   "outputs": [],
   "source": [
    "vis = gensimvis.prepare(topic_model=lda_model, corpus=bow_corpus, dictionary=dictionary)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(vis)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "LDA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (text_mining)",
   "language": "python",
   "name": "text_mining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
