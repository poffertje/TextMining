{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poffertje/TextMining/blob/master/code/fake_classifier/LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GEQXnZletRd"
      },
      "outputs": [],
      "source": [
        "##### This code is strongly based of Amazon review classifier (https://t-lanigan.github.io/amazon-review-classifier/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mounting the Drive (Google Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvuWICD1Budo",
        "outputId": "db3bacab-efb9-4b82-b864-ededa97cc531"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4-v2vHHZF5Qa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import string\n",
        "import joblib\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy as scipy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from six.moves import cPickle as pickle\n",
        "from time import time\n",
        "from pathlib import Path\n",
        "\n",
        "pd.options.display.max_rows = 15\n",
        "np.set_printoptions(precision = 4, suppress=True)\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resolving Paths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Local Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "WNrd0FsOGHku"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\lmps\\github\\TextMining2\\datasets\n",
            "Does path exist? -> True\n",
            "C:\\Users\\lmps\\github\\TextMining2\\models\n",
            "Does path exist? -> True\n",
            "C:\\Users\\lmps\\github\\TextMining2\\models\\fake_classifier\n",
            "Does path exist? -> True\n",
            "C:\\Users\\lmps\\github\\TextMining2\\datasets\\classifier_sample.csv\n",
            "Does path exist? -> True\n"
          ]
        }
      ],
      "source": [
        "CUR_DIR = (\n",
        "    Path().resolve()\n",
        ")  # this should provide you with the folder in which this notebook is placed\n",
        "# use this for local repository\n",
        "PATH_TO_DATASETS = Path.joinpath(CUR_DIR.parents[1], \"datasets\")\n",
        "print(PATH_TO_DATASETS)\n",
        "print(\"Does path exist? ->\", Path.exists(PATH_TO_DATASETS))\n",
        "\n",
        "PATH_TO_MODELS = Path.joinpath(CUR_DIR.parents[1], \"models\")\n",
        "print(PATH_TO_MODELS)\n",
        "print(\"Does path exist? ->\", Path.exists(PATH_TO_DATASETS))\n",
        "\n",
        "PATH_TO_CLASSIFIER = Path.joinpath(PATH_TO_MODELS, \"fake_classifier\")\n",
        "print(PATH_TO_CLASSIFIER)\n",
        "print(\"Does path exist? ->\", Path.exists(PATH_TO_CLASSIFIER))\n",
        "\n",
        "# same for colab and local repository\n",
        "PATH_TO_YELP = Path.joinpath(PATH_TO_DATASETS, \"classifier_sample.csv\")\n",
        "print(PATH_TO_YELP)\n",
        "print(\"Does path exist? ->\", Path.exists(PATH_TO_YELP))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqXJpbku4THE"
      },
      "source": [
        "### Dataset import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "p0F3YefyYuhH"
      },
      "outputs": [],
      "source": [
        "#import dataset\n",
        "dataset = pd.read_csv(PATH_TO_YELP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QHylx26E352F",
        "outputId": "3a49b62c-380d-4a2d-e251-31da12f82a47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of         userID  productID  rating  label        date  \\\n",
              "0         5045          0     1.0      0  2014-09-08   \n",
              "1         5046          0     3.0      0  2013-10-06   \n",
              "2         5047          0     5.0      0  2014-11-30   \n",
              "3         5048          0     5.0      0  2014-08-28   \n",
              "4         5049          0     5.0      0  2013-07-16   \n",
              "...        ...        ...     ...    ...         ...   \n",
              "159491   70576        854     5.0      1  2014-11-26   \n",
              "159492   70577        854     5.0      1  2014-09-14   \n",
              "159493   70578        854     3.0      1  2014-09-10   \n",
              "159494   19199        854     5.0      1  2014-06-08   \n",
              "159495   44466        854     4.0      1  2014-05-08   \n",
              "\n",
              "                                                   review  sentiment label  \\\n",
              "0       This was the worst experience I've ever had a ...                0   \n",
              "1       This is located on the site of the old Spruce ...                0   \n",
              "2       I enjoyed coffee and breakfast twice at Toast ...                1   \n",
              "3       I love Toast! The food choices are fantastic -...                1   \n",
              "4       The egg on an English muffin (their take on eg...                1   \n",
              "...                                                   ...              ...   \n",
              "159491  Finally I found an awesome authentic Italian d...                1   \n",
              "159492  THE best place in the tri-county to get a hero...                1   \n",
              "159493  I am giving this place three stars for their e...                0   \n",
              "159494  Hands down one of the best pork store and deli...                1   \n",
              "159495  Very good italian deli/ market. A definite mus...                1   \n",
              "\n",
              "        review_length  average_product_rating  average_user_rating  \\\n",
              "0                 248                3.662791             1.000000   \n",
              "1                  50                3.662791             3.250000   \n",
              "2                 233                3.662791             5.000000   \n",
              "3                 152                3.662791             5.000000   \n",
              "4                  73                3.662791             5.000000   \n",
              "...               ...                     ...                  ...   \n",
              "159491             40                4.371429             5.000000   \n",
              "159492             25                4.371429             5.000000   \n",
              "159493             85                4.371429             2.500000   \n",
              "159494             97                4.371429             5.000000   \n",
              "159495             75                4.371429             4.272727   \n",
              "\n",
              "        extreme_count_ratio  nr_of_reviews  exclaim_cnt  all_cap  \n",
              "0                       1.0              1            0        4  \n",
              "1                       0.0              4            0        1  \n",
              "2                       0.0              1            2        9  \n",
              "3                       0.0              1            2        3  \n",
              "4                       0.0              1            0        0  \n",
              "...                     ...            ...          ...      ...  \n",
              "159491                  0.0              2            0        1  \n",
              "159492                  0.0              1            0        1  \n",
              "159493                  0.0              2            0        2  \n",
              "159494                  0.0              3            3        2  \n",
              "159495                  0.0             11            0        5  \n",
              "\n",
              "[159496 rows x 14 columns]>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# show dataset\n",
        "dataset.head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUoTtNwRwS5U"
      },
      "source": [
        "### Dataset splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oDEpW1jqzUP2"
      },
      "outputs": [],
      "source": [
        "# split the dataset into \n",
        "x_train, x_test, y_train, y_test = train_test_split(dataset, dataset['label'],test_size=0.2, random_state=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-kt7KyL9e8I",
        "outputId": "4ac2dd07-9fb9-4897-fa77-25aef4adaaab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label\n",
              "1    64050\n",
              "0    63546\n",
              "dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check train set label distribution\n",
        "x_train.value_counts(\"label\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "937-mlgMwYWm"
      },
      "source": [
        "### Creating correlation matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jW5tLZ71sA-E"
      },
      "outputs": [],
      "source": [
        "# generate correlation table from training data\n",
        "correlation_table = x_train.corr().round(decimals=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NW75ymG4J4u1"
      },
      "outputs": [],
      "source": [
        "# export correlation table\n",
        "# correlation_table.to_csv(\"/content/gdrive/Shareddrives/Minecraft/Our_Models/LogisticRegression/correlation_table.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MI9EaiHDycqs"
      },
      "outputs": [],
      "source": [
        "#define our own tokenizing function that we will pass into the TFIDFVectorizer. We will also stem the words here.\n",
        "def tokens(x):\n",
        "    x = x.split()\n",
        "    stems = []\n",
        "    [stems.append(stemmer.stem(word)) for word in x]\n",
        "    return stems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxXGzKuswx_r"
      },
      "source": [
        "### Defining helper methods\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "mrwgXyxnIN_O"
      },
      "outputs": [],
      "source": [
        "# helper function for removing punctuation\n",
        "def remove_punctuation(text):\n",
        "  return text.translate(str.maketrans('', '', string.punctuation))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0G9i5OBwIJOs"
      },
      "outputs": [],
      "source": [
        "# count number of exclamation marks\n",
        "def count_exlaim(review):\n",
        "    count = 0\n",
        "    for i in range(len(review)):\n",
        "        if review[i] == '!':\n",
        "            count += 1\n",
        "    return count\n",
        "\n",
        "# count number of capital words\n",
        "def count_caps(review):\n",
        "    count = 0\n",
        "    for item in review.split():\n",
        "        if item.isupper():\n",
        "            count += 1\n",
        "    return count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "KaabVfUzk3wA"
      },
      "outputs": [],
      "source": [
        "# additional columns to be added to input data\n",
        "def adding_columns(data):\n",
        "  data[\"review_length\"] = data['review'].str.split().str.len()\n",
        "  data[\"average_product_rating\"] = data.groupby('productID')['rating'].transform('mean')\n",
        "  data[\"average_user_rating\"] = data.groupby('userID')['rating'].transform('mean')\n",
        "  nr_rows = data.groupby('userID').size().astype(float).reset_index(name=\"nr of rows\")\n",
        "  extreme_count = (data.groupby('userID')['rating'].apply(lambda x: (x == (1.0 or 5.0) ).sum())).reset_index(name=\"extreme_count_ratio\")\n",
        "  extreme_count[\"extreme_count_ratio\"] = extreme_count[\"extreme_count_ratio\"].astype(float).div(nr_rows[\"nr of rows\"].values,axis=0)\n",
        "  data = pd.merge(data, extreme_count, how='left', on = 'userID')\n",
        "  data[\"nr_of_reviews\"] = data.groupby('userID')[\"userID\"].transform('count')\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "cxwE70gfdETc"
      },
      "outputs": [],
      "source": [
        "# convert input data to features (input for the model)\n",
        "def features_conversion(data):\n",
        "  # drop NaN rows\n",
        "  data = data.dropna()\n",
        "  data.loc[:, 'review'] = data['review'].str.lower()\n",
        "  data['review']=data['review'].apply( lambda x: remove_punctuation(x))\n",
        "  vectorizer = joblib.load(Path.joinpath(PATH_TO_CLASSIFIER, 'vectorizer.pickle'))\n",
        "  features_created = vectorizer.transform(data['review'])\n",
        "  length = np.array(list(data.review_length)).reshape(features_created.shape[0], 1)\n",
        "  features_created = scipy.sparse.hstack((features_created,scipy.sparse.csr_matrix(length)))\n",
        "  xtreme_ratio = np.array(list(data.extreme_count_ratio)).reshape(features_created.shape[0],1)\n",
        "  features_created = scipy.sparse.hstack((features_created,scipy.sparse.csr_matrix(xtreme_ratio)))\n",
        "  features_created = scipy.sparse.csr_matrix(features_created)\n",
        "  return features_created"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating feature space for LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pickled file already present, loading...\n",
            "Pickle file loaded.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<127596x841 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 4038423 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#create a stemmer\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "#loads pickle if exists, extracts and pickles if it doesn't\n",
        "if os.path.exists(Path.joinpath(PATH_TO_CLASSIFIER, 'features.pickle')) and os.path.exists(Path.joinpath(PATH_TO_CLASSIFIER, 'vectorizer.pickle')):\n",
        "    print ('Pickled file already present, loading...')\n",
        "    features = pickle.load(open(Path.joinpath(PATH_TO_CLASSIFIER, 'features.pickle'), \"rb\" ))\n",
        "    vectorizer = pickle.load(open(Path.joinpath(PATH_TO_CLASSIFIER, 'vectorizer.pickle'), \"rb\") )\n",
        "    print ('Pickle file loaded.')\n",
        "else:\n",
        "    #define the vectorizer\n",
        "    vectorizer = TfidfVectorizer(tokenizer = tokens, stop_words = 'english', ngram_range=(1, 3), min_df = 0.01)\n",
        "    #fit the vectorizers to the data.\n",
        "    x_train.loc[:, 'review'] = x_train['review'].str.lower()\n",
        "    x_train['review']=x_train['review'].apply( lambda x: remove_punctuation(x))\n",
        "    features = vectorizer.fit_transform(x_train['review'].values.astype(str))\n",
        "    length = np.array(list(x_train.review_length)).reshape(features.shape[0], 1)\n",
        "    xtreme_ratio = np.array(list(x_train.extreme_count_ratio)).reshape(features.shape[0],1)\n",
        "    features = scipy.sparse.hstack((features,scipy.sparse.csr_matrix(length)))\n",
        "    features = scipy.sparse.hstack((features,scipy.sparse.csr_matrix(xtreme_ratio)))\n",
        "    features = scipy.sparse.csr_matrix(features)\n",
        "    pickle.dump(features, open(Path.joinpath(PATH_TO_CLASSIFIER, 'features.pickle'), \"wb\"))\n",
        "    pickle.dump(vectorizer, open(Path.joinpath(PATH_TO_CLASSIFIER, 'vectorizer.pickle'), \"wb\"))\n",
        "\n",
        "features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFFisa7Kw378"
      },
      "source": [
        "### Convert data to features (compatible with feature space)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSwIf6BC2BIh"
      },
      "outputs": [],
      "source": [
        "# convert training data to features\n",
        "x_train = features_conversion(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4VHCv3C2IyC"
      },
      "outputs": [],
      "source": [
        "# convert testing data to features\n",
        "x_test = features_conversion(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIye9ZDUw8za"
      },
      "source": [
        "### Training classifier and export model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHMdBDEj7lMo"
      },
      "outputs": [],
      "source": [
        "# to train (and store) classifier model\n",
        "def train_classifier(clf, X_train, y_train, store=False,name=None):\n",
        "    ''' Fits a classifier to the training data. '''\n",
        "    \n",
        "    # Start the clock, train the classifier, then stop the clock\n",
        "    start = time()\n",
        "    clf.fit(X_train, y_train)\n",
        "    end = time()\n",
        "    \n",
        "    if store == True:\n",
        "      filename = name\n",
        "      joblib.dump(clf, Path.joinpath(PATH_TO_CLASSIFIER, filename))\n",
        "    # Print the results\n",
        "    print (\"Trained model in {:.4f} seconds\".format(end - start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyCMTOjr6yX1",
        "outputId": "9e6d2baf-36f4-4fd7-d088-88d77c041081"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trained model in 3.0388 seconds\n"
          ]
        }
      ],
      "source": [
        "# train classifier and store model\n",
        "# os.chdir('/content/gdrive/Shareddrives/Minecraft/Our_Models/LogisticRegression/')\n",
        "train_classifier(LogisticRegression(), x_train, y_train, True, \"finalized_model.sav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moMMSweqZMxr"
      },
      "outputs": [],
      "source": [
        "# load in model\n",
        "final_model = joblib.load(Path.joinpath(PATH_TO_CLASSIFIER, 'finalized_model.sav'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_9xWpR_6XQd"
      },
      "source": [
        "### Classification report on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUxmruC74l5k",
        "outputId": "21490451-62ca-4a8d-fe9a-b27d43f7bee2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.71      0.69     15953\n",
            "           1       0.69      0.66      0.68     16047\n",
            "\n",
            "    accuracy                           0.68     32000\n",
            "   macro avg       0.68      0.68      0.68     32000\n",
            "weighted avg       0.68      0.68      0.68     32000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# generate and show classification report\n",
        "print(classification_report(y_test, final_model.predict(x_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wmk8QdlKxIKH"
      },
      "source": [
        "### Processing production test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rj95xcBsns4Y"
      },
      "outputs": [],
      "source": [
        "# read in the file\n",
        "test_1814 = pd.read_csv(Path.joinpath(PATH_TO_DATASETS, 'production_set.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwQFCDcVSevT"
      },
      "outputs": [],
      "source": [
        "# encoding the labels from -1 and 1 to 0 and 1\n",
        "encode_label = {-1 : 0, 1 : 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yt7XzKiYSkWL"
      },
      "outputs": [],
      "source": [
        "# encoding \n",
        "test_1814['label'] = test_1814['label'].map(encode_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gfo9TmS0D5DB",
        "outputId": "2a6ba1f6-e6e6-4972-f27d-0b6498de3a50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label\n",
              "1    167\n",
              "0     33\n",
              "dtype: int64"
            ]
          },
          "execution_count": 278,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check distribution of target label in production test set\n",
        "test_1814.value_counts(\"label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgGUxvu8lDJ6"
      },
      "outputs": [],
      "source": [
        "# add additional columns to be intepretable for the model\n",
        "test_1814 = adding_columns(test_1814)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apWt_TGznwWk"
      },
      "outputs": [],
      "source": [
        "# convert dataframe to features\n",
        "test_1814_features = features_conversion(test_1814)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aBelMTbxTRi"
      },
      "source": [
        "### Classification report on production test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9S3Sl0ilZ20",
        "outputId": "65ac4c9a-04cd-4b57-d6ec-526772691779"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      0.64      0.39        33\n",
            "           1       0.90      0.68      0.78       167\n",
            "\n",
            "    accuracy                           0.68       200\n",
            "   macro avg       0.59      0.66      0.59       200\n",
            "weighted avg       0.80      0.68      0.71       200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# generate and show classification report\n",
        "print(classification_report(test_1814[\"label\"], final_model.predict(test_1814_features)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "machine_shape": "hm",
      "name": "Logistic Regression fake classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (text_mining)",
      "language": "python",
      "name": "text_mining"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
