{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FTBERT-evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poffertje/TextMining/blob/master/code/sentiment_analysis/FTBERT_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code to Evaluation Our Fine-tuned BERT Models \n",
        "The code is heavily based on: https://www.coursera.org/learn/fine-tune-bert-tensorflow/ungradedLti/ack5t/fine-tune-bert-for-text-classification-with-tensorflow"
      ],
      "metadata": {
        "id": "uc6DutjgoCOR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUZLVBmXLd8-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f1f3965-fab4-4b95-cf2f-f03f93ae6300"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/Shareddrives/Minecraft/Datasets')"
      ],
      "metadata": {
        "id": "Su7aPZeTqRnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports and Installations"
      ],
      "metadata": {
        "id": "fRHbXwr8okrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pB9WIBFXrXUQ",
        "outputId": "0a3df28d-d7d8-4302-d510-d789c0365fc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --depth 1 -b v2.3.0 https://github.com/tensorflow/models.git\n",
        "!pip install -q tf-models-official==2.4.0\n",
        "!pip install -q transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcgxJzsnrXhP",
        "outputId": "ccb8987e-6461-4969-9838-83eccacb101b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'models' already exists and is not an empty directory.\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 14.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 72.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 73.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 67.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 12.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.8 MB 105 kB/s \n",
            "\u001b[K     |████████████████████████████████| 237 kB 104.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 85.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 67.0 MB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 14.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 70.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 77 kB 8.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 52.8 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_hub as hub\n",
        "from official.nlp.data import classifier_data_lib\n",
        "from official.nlp.bert import tokenization\n",
        "from official.nlp import optimization\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "gWe7PC_6rXyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TF Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDnZPrwtrgz2",
        "outputId": "77f3cc0d-acaa-4dbf-df2b-c55282ee77fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF Version:  2.8.0\n",
            "Eager mode:  True\n",
            "Hub version:  0.12.0\n",
            "GPU is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the Datasets"
      ],
      "metadata": {
        "id": "APfKrenQombB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = pd.read_csv('test_sample24.csv')\n",
        "full_prod_test_set = pd.read_csv('8April_production_set.csv')"
      ],
      "metadata": {
        "id": "avZHn0-tr0go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definining Constant Parameters"
      ],
      "metadata": {
        "id": "85WA1rogxNtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.6\n",
        "label_list = [0, 1] # Label categories\n",
        "max_seq_length = 128 # maximum length of (token) input sequences\n",
        "true_labels = test_set['sentiment label']\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\",\n",
        "                            trainable=True)\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
        "\n"
      ],
      "metadata": {
        "id": "DojTGQf7u_-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_prod_true_labels = full_prod_test_set['sentiment label']"
      ],
      "metadata": {
        "id": "nAyKCsBXNx9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions to Preprocess Text Input"
      ],
      "metadata": {
        "id": "Ochc1WaysNTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_feature(text, label, label_list=label_list, max_seq_length=max_seq_length, tokenizer=tokenizer):\n",
        "  example = classifier_data_lib.InputExample(guid = None,\n",
        "                                            text_a = text.numpy(), \n",
        "                                            text_b = None, \n",
        "                                            label = label.numpy())\n",
        "  feature = classifier_data_lib.convert_single_example(0, example, label_list,\n",
        "                                    max_seq_length, tokenizer)\n",
        "  \n",
        "  return (feature.input_ids, feature.input_mask, feature.segment_ids, feature.label_id)"
      ],
      "metadata": {
        "id": "X0Z3At44sMDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#wrapper function \n",
        "def to_feature_map(text, label):\n",
        "  input_ids, input_mask, segment_ids, label_id = tf.py_function(to_feature, inp=[text, label], \n",
        "                                Tout=[tf.int32, tf.int32, tf.int32, tf.int32])\n",
        "  input_ids.set_shape([max_seq_length])\n",
        "  input_mask.set_shape([max_seq_length])\n",
        "  segment_ids.set_shape([max_seq_length])\n",
        "  label_id.set_shape([])\n",
        "\n",
        "  x = {\n",
        "        'input_word_ids': input_ids,\n",
        "        'input_mask': input_mask,\n",
        "        'input_type_ids': segment_ids\n",
        "    }\n",
        "  return (x, label_id)"
      ],
      "metadata": {
        "id": "oaJQg7ipte4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creation of Custom Layer"
      ],
      "metadata": {
        "id": "x_DO5knkt1WT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropout = 0.3\n",
        "def create_model():\n",
        "  input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                      name=\"input_word_ids\")\n",
        "  input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                  name=\"input_mask\")\n",
        "  input_type_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                  name=\"input_type_ids\")\n",
        "\n",
        "  pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, input_type_ids])\n",
        "\n",
        "  drop = tf.keras.layers.Dropout(dropout)(pooled_output)\n",
        "  output = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"output\")(drop)\n",
        "\n",
        "  model = tf.keras.Model(\n",
        "    inputs={\n",
        "        'input_word_ids': input_word_ids,\n",
        "        'input_mask': input_mask,\n",
        "        'input_type_ids': input_type_ids\n",
        "    },\n",
        "    outputs=output)\n",
        "  return model"
      ],
      "metadata": {
        "id": "ovIVCUE2t0oQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction Function"
      ],
      "metadata": {
        "id": "W3kqKdpkuO8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_labels(sample_data,model):\n",
        "  test_data = tf.data.Dataset.from_tensor_slices((sample_data, [0]*len(sample_data)))\n",
        "  test_data = (test_data.map(to_feature_map).batch(1))\n",
        "  preds = model.predict(test_data)\n",
        "  return preds"
      ],
      "metadata": {
        "id": "qrz5-DUCuNmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_from_threshold(sample_data, model, threshold):\n",
        "  pred_probs = predict_labels(sample_data,model)\n",
        "  predicted = [1 if pred > threshold else 0 for pred in pred_probs]\n",
        "  return predicted"
      ],
      "metadata": {
        "id": "YaziV5_UuwO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation of Model trained on Imbalanced Training Set"
      ],
      "metadata": {
        "id": "FXjBPjbGomkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\",\n",
        "                            trainable=True)\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "metadata": {
        "id": "keD6_gG6r671"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imbalanced_model = create_model()\n",
        "imbalanced_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5, epsilon=1e-08, clipnorm=1.0),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
        "imbalanced_model.load_weights('100k-2e5-16-02-8April_sentiment_sample_25_75_mixed_weights')\n",
        "imbalanced_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMQmB5Err7e-",
        "outputId": "a201e104-3a2d-453f-ced0-688f91ee6b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_word_ids (InputLayer)    [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " input_mask (InputLayer)        [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " input_type_ids (InputLayer)    [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " keras_layer_1 (KerasLayer)     [(None, 768),        109482241   ['input_word_ids[0][0]',         \n",
            "                                 (None, 128, 768)]                'input_mask[0][0]',             \n",
            "                                                                  'input_type_ids[0][0]']         \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 768)          0           ['keras_layer_1[0][0]']          \n",
            "                                                                                                  \n",
            " output (Dense)                 (None, 1)            769         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,483,010\n",
            "Trainable params: 109,483,009\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Evaluation of Model on Development Test Set"
      ],
      "metadata": {
        "id": "CgNE6LL54BTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imbalance_pred_labels = convert_from_threshold(test_set['review'],imbalanced_model,threshold)"
      ],
      "metadata": {
        "id": "6262Keucr7uY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(true_labels,imbalance_pred_labels))"
      ],
      "metadata": {
        "id": "xDHXHtdjvgPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Evaluation of Model on Production Test Set"
      ],
      "metadata": {
        "id": "gGq0ZOcW4Jbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imbal_full_prod_pred_labels = convert_from_threshold(full_prod_test_set['review'],imbalanced_model,threshold)"
      ],
      "metadata": {
        "id": "IoQJnBVmJ7BM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(full_prod_true_labels,imbal_full_prod_pred_labels))"
      ],
      "metadata": {
        "id": "kN7xkKa9KzSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation of Model trained on Balanced Training Set"
      ],
      "metadata": {
        "id": "WuoxBg4gomsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get BERT layer and tokenizer:\n",
        "# More details here: https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\",\n",
        "                            trainable=True)\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "metadata": {
        "id": "t3PMt5zpwrWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_model = create_model()\n",
        "balanced_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5, epsilon=1e-08, clipnorm=1.0),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
        "#balanced_model.load_weights('100k-b16-2e5-dropout03-apr8-mixed-50-50_bert_weights')\n",
        "balanced_model.load_weights('b16-2e5-dropout03-apr8-mixed-50-50_bert_weights')\n",
        "balanced_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLynuURWwrWk",
        "outputId": "2214fc67-e2f8-4856-e328-0ddafa2b428b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_word_ids (InputLayer)    [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " input_mask (InputLayer)        [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " input_type_ids (InputLayer)    [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " keras_layer_12 (KerasLayer)    [(None, 768),        109482241   ['input_word_ids[0][0]',         \n",
            "                                 (None, 128, 768)]                'input_mask[0][0]',             \n",
            "                                                                  'input_type_ids[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 768)          0           ['keras_layer_12[0][0]']         \n",
            "                                                                                                  \n",
            " output (Dense)                 (None, 1)            769         ['dropout_9[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,483,010\n",
            "Trainable params: 109,483,009\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Evaluation of Model on Development Test Set"
      ],
      "metadata": {
        "id": "uGWXrODR4eQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "balance_pred_labels = convert_from_threshold(test_set['review'],balanced_model,threshold)"
      ],
      "metadata": {
        "id": "PQ-o_ZFKwrWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(true_labels,balance_pred_labels))"
      ],
      "metadata": {
        "id": "rpxCuAV_wrWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Evaluation of Model on Production Test Set"
      ],
      "metadata": {
        "id": "uQtgp-Bc4iat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bal_full_prod_pred_labels = convert_from_threshold(test_set['review'],balanced_model,threshold)\n",
        "print(classification_report(full_prod_true_labels,bal_full_prod_pred_labels))"
      ],
      "metadata": {
        "id": "o9bJH2WAPDAA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}